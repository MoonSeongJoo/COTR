{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import subprocess\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# import torch.multiprocessing\n",
    "# torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from COTR.models import build_model\n",
    "from COTR.utils import debug_utils, utils\n",
    "# from COTR.datasets import cotr_dataset\n",
    "from COTR.trainers.cotr_trainer import COTRTrainer\n",
    "from COTR.global_configs import general_config\n",
    "from COTR.options.options import *\n",
    "from COTR.options.options_utils import *\n",
    "from COTR_DatasetLidarCamera_Ver5 import DatasetLidarCameraKittiOdometry\n",
    "from utils import (mat2xyzrpy, merge_inputs, overlay_imgs, quat2mat,\n",
    "                   quaternion_from_matrix, rotate_back, rotate_forward,\n",
    "                   tvector2mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'ignore'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.fix_randomness(0)\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt):\n",
    "    pprint.pprint(dict(os.environ), width=1)\n",
    "    result = subprocess.Popen([\"nvidia-smi\"], stdout=subprocess.PIPE)\n",
    "    print(result.stdout.read().decode())\n",
    "    device = torch.cuda.current_device()\n",
    "    print(f'can see {torch.cuda.device_count()} gpus')\n",
    "    print(f'current using gpu at {device} -- {torch.cuda.get_device_name(device)}')\n",
    "    # dummy = torch.rand(3758725612).to(device)\n",
    "    # del dummy\n",
    "    torch.cuda.empty_cache()\n",
    "    model = build_model(opt)\n",
    "    model = model.to(device)\n",
    "    dataset_class = DatasetLidarCameraKittiOdometry\n",
    "#     if opt.enable_zoom:\n",
    "#         train_dset = cotr_dataset.COTRZoomDataset(opt, 'train')\n",
    "#         val_dset = cotr_dataset.COTRZoomDataset(opt, 'val')\n",
    "#     else:\n",
    "#         train_dset = cotr_dataset.COTRDataset(opt, 'train')\n",
    "#         val_dset = cotr_dataset.COTRDataset(opt, 'val')\n",
    "\n",
    "    dataset_train = dataset_class(\"/mnt/data/kitti_odometry\", max_r=10.0, max_t=0.2,\n",
    "                                  split='train', use_reflectance=False,\n",
    "                                  val_sequence= '00')\n",
    "    \n",
    "    dataset_val = dataset_class(\"/mnt/data/kitti_odometry\", max_r=10.0, max_t=0.2,\n",
    "                                split='val', use_reflectance=False,\n",
    "                                val_sequence='00')\n",
    "    \n",
    "    train_dataset_size = len(dataset_train)\n",
    "    val_dataset_size = len(dataset_val)\n",
    "    print('Number of the train dataset: {}'.format(train_dataset_size))\n",
    "    print('Number of the val dataset: {}'.format(val_dataset_size))\n",
    "\n",
    "    train_loader = DataLoader(dataset_train, batch_size=opt.batch_size,\n",
    "                              shuffle=opt.shuffle_data, num_workers=opt.workers,\n",
    "                              worker_init_fn=utils.worker_init_fn, collate_fn=merge_inputs,drop_last=False,pin_memory=True)\n",
    "    val_loader   = DataLoader(dataset_val, batch_size=opt.batch_size,\n",
    "                              shuffle=opt.shuffle_data, num_workers=opt.workers,\n",
    "                              worker_init_fn=utils.worker_init_fn,collate_fn=merge_inputs,drop_last=False, pin_memory=True)\n",
    "    optim_list = [{\"params\": model.transformer.parameters(), \"lr\": opt.learning_rate},\n",
    "                  {\"params\": model.corr_embed.parameters(), \"lr\": opt.learning_rate},\n",
    "                  {\"params\": model.query_proj.parameters(), \"lr\": opt.learning_rate},\n",
    "                  {\"params\": model.input_proj.parameters(), \"lr\": opt.learning_rate},\n",
    "                  ]\n",
    "    if opt.lr_backbone > 0:\n",
    "        optim_list.append({\"params\": model.backbone.parameters(), \"lr\": opt.lr_backbone})\n",
    "    optim = torch.optim.Adam(optim_list)\n",
    "    trainer = COTRTrainer(opt, model, optim, None, train_loader, val_loader)\n",
    "    trainer.train()\n",
    "    print(\"train epoch end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resuming from last run\n",
      "---------------------- OPTIONS ----------------------\n",
      "\n",
      "                 backbone  resnet50\n",
      "               batch_size  1\n",
      "            bidirectional  False\n",
      "                cc_resume  True\n",
      "                  command  /root/venv/lib/python3.8/site-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-efe1835b-ce47-4d66-afc5-06719d35380c.json\n",
      "                  confirm  True\n",
      "                 crop_cam  crop_center_and_resize\n",
      "             cycle_consis  True\n",
      "             dataset_name  megadepth\n",
      "               dec_layers  6\n",
      "                 dilation  False\n",
      "          dim_feedforward  1024\n",
      "                  dropout  0.1\n",
      "              enable_zoom  False\n",
      "               enc_layers  6\n",
      "               hidden_dim  256\n",
      "               info_level  rgbd\n",
      "                   k_size  1\n",
      "                  kp_pool  100\n",
      "                    layer  layer3\n",
      "            learning_rate  0.0001\n",
      "             load_weights  None\n",
      "        load_weights_path  /root/work/COTR/out/default/checkpoint.pth.tar\n",
      "              lr_backbone  1e-05\n",
      "                 max_iter  200000\n",
      "             max_rotation  0\n",
      "                     name  default\n",
      "            need_rotation  False\n",
      "                   nheads  8\n",
      "                nn_method  overlapping\n",
      "                   num_kp  100\n",
      "              num_queries  100\n",
      "                      out  /root/work/COTR/out/default\n",
      "                  out_dir  /root/work/COTR/out/\n",
      "                pool_size  20\n",
      "       position_embedding  lin_sine\n",
      "                   resume  True\n",
      "          rotation_chance  0\n",
      "               scene_file  None\n",
      "             shuffle_data  True\n",
      "                   suffix  \n",
      "                   tb_dir  /root/work/COTR/out/tb\n",
      "                   tb_out  /root/work/COTR/out/tb/default\n",
      "                   use_cc  False\n",
      "                 use_cuda  True\n",
      "                  use_ram  False\n",
      "               valid_iter  1000\n",
      "                  workers  10\n",
      "                 zoom_end  0.1\n",
      "              zoom_jitter  0.5\n",
      "              zoom_levels  10\n",
      "               zoom_start  1.0\n",
      "\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OK to continue? [y/n]  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CLICOLOR': '1',\n",
      " 'CRC32C_SW_MODE': 'auto',\n",
      " 'DISPLAY': '204a4a851509:10.0',\n",
      " 'GIT_PAGER': 'cat',\n",
      " 'HOME': '/root',\n",
      " 'JPY_PARENT_PID': '579564',\n",
      " 'KMP_DUPLICATE_LIB_OK': 'True',\n",
      " 'KMP_INIT_AT_FORK': 'FALSE',\n",
      " 'LANG': 'en.UTF-8',\n",
      " 'LANGUAGE': 'en.UTF-8',\n",
      " 'LC_ADDRESS': 'C.UTF-8',\n",
      " 'LC_CTYPE': 'C.UTF-8',\n",
      " 'LC_IDENTIFICATION': 'C.UTF-8',\n",
      " 'LC_MEASUREMENT': 'C.UTF-8',\n",
      " 'LC_MONETARY': 'C.UTF-8',\n",
      " 'LC_NAME': 'C.UTF-8',\n",
      " 'LC_NUMERIC': 'C.UTF-8',\n",
      " 'LC_PAPER': 'C.UTF-8',\n",
      " 'LC_TELEPHONE': 'C.UTF-8',\n",
      " 'LC_TIME': 'C.UTF-8',\n",
      " 'LESSCLOSE': '/usr/bin/lesspipe '\n",
      "              '%s '\n",
      "              '%s',\n",
      " 'LESSOPEN': '| '\n",
      "             '/usr/bin/lesspipe '\n",
      "             '%s',\n",
      " 'LOGNAME': 'root',\n",
      " 'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:',\n",
      " 'MAIL': '/var/mail/root',\n",
      " 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline',\n",
      " 'OLDPWD': '/root',\n",
      " 'PAGER': 'cat',\n",
      " 'PATH': '/root/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
      " 'PS1': '(venv) '\n",
      "        '\\\\[\\\\e]0;\\\\u@\\\\h: '\n",
      "        '\\\\w\\\\a\\\\]${debian_chroot:+($debian_chroot)}\\\\u@\\\\h:\\\\w\\\\$ ',\n",
      " 'PWD': '/root/.jupyter',\n",
      " 'QT_QPA_FONTDIR': '/root/venv/lib/python3.8/site-packages/cv2/qt/fonts',\n",
      " 'QT_QPA_PLATFORM_PLUGIN_PATH': '/root/venv/lib/python3.8/site-packages/cv2/qt/plugins',\n",
      " 'SHELL': '/bin/bash',\n",
      " 'SHLVL': '1',\n",
      " 'SSH_CLIENT': '175.207.72.235 '\n",
      "               '50830 '\n",
      "               '22',\n",
      " 'SSH_CONNECTION': '175.207.72.235 '\n",
      "                   '50830 '\n",
      "                   '172.17.0.5 '\n",
      "                   '22',\n",
      " 'SSH_TTY': '/dev/pts/0',\n",
      " 'TERM': 'xterm-color',\n",
      " 'USER': 'root',\n",
      " 'VIRTUAL_ENV': '/root/venv',\n",
      " '_': '/root/venv/bin/jupyter'}\n",
      "Thu Mar 17 19:51:16 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:68:00.0 Off |                  N/A |\n",
      "|  0%   27C    P8     1W / 280W |     15MiB / 24217MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "can see 1 gpus\n",
      "current using gpu at 0 -- TITAN RTX\n",
      "using lin_sine as positional encoding\n",
      "freeze conv1.weight\n",
      "freeze layer1.0.conv1.weight\n",
      "freeze layer1.0.conv2.weight\n",
      "freeze layer1.0.conv3.weight\n",
      "freeze layer1.0.downsample.0.weight\n",
      "freeze layer1.1.conv1.weight\n",
      "freeze layer1.1.conv2.weight\n",
      "freeze layer1.1.conv3.weight\n",
      "freeze layer1.2.conv1.weight\n",
      "freeze layer1.2.conv2.weight\n",
      "freeze layer1.2.conv3.weight\n",
      "freeze fc.weight\n",
      "freeze fc.bias\n",
      "using lin_sine as positional encoding\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 11.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 12.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 13.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 14.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 15.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 16.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 17.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 18.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 19.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 20.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 21.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 11.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 12.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 13.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 14.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 15.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 16.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 17.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 18.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 19.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 20.\n",
      "-pose_path- /mnt/data/kitti_odometry/data_odometry_poses/dataset/poses\n",
      "Ground truth poses are not avaialble for sequence 21.\n",
      "Number of the train dataset: 39011\n",
      "Number of the val dataset: 4541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                                              | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights safely loaded\n",
      "---------------------- NOTIFICATION ----------------------\n",
      "\n",
      "Loaded pretrained weights from /root/work/COTR/out/default/checkpoint.pth.tar\n",
      "\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train epoch=0:  97%|█████████████████████████████▏| 38000/39011 [00:00<?, ?it/s]\u001b[A/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                           | 0/4541 [00:00<?, ?it/s]\u001b[A\u001b[A/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
      "/root/work/COTR/COTR_DatasetLidarCamera_Ver5.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                | 1/4541 [00:08<10:40:25,  8.46s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                 | 2/4541 [00:08<4:36:50,  3.66s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                 | 3/4541 [00:09<2:39:58,  2.12s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                 | 4/4541 [00:09<1:43:07,  1.36s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                 | 5/4541 [00:09<1:12:42,  1.04it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                   | 6/4541 [00:09<53:43,  1.41it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                   | 7/4541 [00:10<43:41,  1.73it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                   | 8/4541 [00:10<36:06,  2.09it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                   | 9/4541 [00:10<33:06,  2.28it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                  | 10/4541 [00:11<33:25,  2.26it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                | 11/4541 [00:14<1:30:51,  1.20s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                | 12/4541 [00:14<1:11:23,  1.06it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                  | 13/4541 [00:14<57:03,  1.32it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                  | 14/4541 [00:15<47:02,  1.60it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                  | 15/4541 [00:15<37:53,  1.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=38000:   0%|                  | 16/4541 [00:15<30:31,  2.47it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n",
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                  | 17/4541 [00:15<27:21,  2.76it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                  | 18/4541 [00:15<24:27,  3.08it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid iteration=38000:   0%|                  | 19/4541 [00:16<22:30,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=38000:   0%|                  | 20/4541 [00:16<19:33,  3.85it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape torch.Size([1, 3, 192, 1280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train epoch=0:  97%|█████████████████████████████▏| 38000/39011 [00:27<?, ?it/s]\u001b[A\u001b[A\n",
      "Train:   0%|                                              | 0/6 [00:30<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e094720c48e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mprint_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m#     save_opt(opt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-c7a3b1309df6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptim_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOTRTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train epoch end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/COTR/COTR/trainers/base_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Prevent possible deadlock during epoch transition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/COTR/COTR/trainers/base_trainer.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_iter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Prevent possible deadlock during epoch transition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_pack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/COTR/COTR/trainers/cotr_trainer.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mval_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         for batch_idx, data_pack in tqdm.tqdm(\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Valid iteration=%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    set_general_arguments(parser)\n",
    "    set_dataset_arguments(parser)\n",
    "    set_nn_arguments(parser)\n",
    "    set_COTR_arguments(parser)\n",
    "    parser.add_argument('--num_kp', type=int,\n",
    "                        default=100)\n",
    "    parser.add_argument('--kp_pool', type=int,\n",
    "                        default=100)\n",
    "    parser.add_argument('--enable_zoom', type=str2bool,\n",
    "                        default=False)\n",
    "    parser.add_argument('--zoom_start', type=float,\n",
    "                        default=1.0)\n",
    "    parser.add_argument('--zoom_end', type=float,\n",
    "                        default=0.1)\n",
    "    parser.add_argument('--zoom_levels', type=int,\n",
    "                        default=10)\n",
    "    parser.add_argument('--zoom_jitter', type=float,\n",
    "                        default=0.5)\n",
    "    parser.add_argument('--out_dir', type=str, default=general_config['out'], help='out directory')\n",
    "    parser.add_argument('--tb_dir', type=str, default=general_config['tb_out'], help='tensorboard runs directory')\n",
    "    parser.add_argument('--learning_rate', type=float,\n",
    "                        default=1e-4, help='learning rate')\n",
    "    parser.add_argument('--lr_backbone', type=float,\n",
    "                        default=1e-5, help='backbone learning rate')\n",
    "    parser.add_argument('--batch_size', type=int,\n",
    "                        default=1, help='batch size for training')\n",
    "    parser.add_argument('--cycle_consis', type=str2bool, default=True,\n",
    "                        help='cycle consistency')\n",
    "    parser.add_argument('--bidirectional', type=str2bool, default=False,\n",
    "                        help='left2right and right2left')\n",
    "    parser.add_argument('--max_iter', type=int,\n",
    "                        default=200000, help='total training iterations')\n",
    "    parser.add_argument('--valid_iter', type=int,\n",
    "                        default=1000, help='iterval of validation')\n",
    "    #parser.add_argument('--resume', type=str2bool, default=True,\n",
    "    #                    help='resume training with same model name')\n",
    "    parser.add_argument('--resume', type=str2bool, default=False,\n",
    "                        help='resume training with same model name')\n",
    "    parser.add_argument('--cc_resume', type=str2bool, default=True,\n",
    "                        help='resume from last run if possible')\n",
    "    parser.add_argument('--need_rotation', type=str2bool, default=False,\n",
    "                        help='rotation augmentation')\n",
    "    parser.add_argument('--max_rotation', type=float, default=0,\n",
    "                        help='max rotation for data augmentation')\n",
    "    parser.add_argument('--rotation_chance', type=float, default=0,\n",
    "                        help='the probability of being rotated')\n",
    "    parser.add_argument('--load_weights', type=str, default=None, help='load a pretrained set of weights, you need to provide the model id')\n",
    "    parser.add_argument('--suffix', type=str, default='', help='model suffix')\n",
    "#     opt = parser.parse_args()\n",
    "    opt = parser.parse_args(args=[])\n",
    "    opt.command = ' '.join(sys.argv)\n",
    "    layer_2_channels = {'layer1': 256,\n",
    "                        'layer2': 512,\n",
    "                        'layer3': 1024,\n",
    "                        'layer4': 2048, }\n",
    "    opt.dim_feedforward = layer_2_channels[opt.layer]\n",
    "    opt.num_queries = opt.num_kp\n",
    "#     opt.name = get_compact_naming_cotr(opt)\n",
    "    opt.out_dir = '/root/work/COTR/out/'\n",
    "    opt.tb_dir = '/root/work/COTR/out/tb'\n",
    "    opt.name = 'default'\n",
    "    opt.out = os.path.join(opt.out_dir, opt.name)\n",
    "    opt.tb_out = os.path.join(opt.tb_dir, opt.name)\n",
    "    if opt.cc_resume:\n",
    "        if os.path.isfile(os.path.join(opt.out, 'checkpoint.pth.tar')):\n",
    "            print('resuming from last run')\n",
    "            opt.load_weights = None\n",
    "            opt.resume = True\n",
    "        else:\n",
    "            opt.resume = False\n",
    "    assert (bool(opt.load_weights) and opt.resume) == False\n",
    "    if opt.load_weights:\n",
    "        opt.load_weights_path = os.path.join(opt.out_dir, opt.load_weights, 'checkpoint.pth.tar')\n",
    "    if opt.resume:\n",
    "        opt.load_weights_path = os.path.join(opt.out, 'checkpoint.pth.tar')\n",
    "#     opt.scenes_name_list = build_scenes_name_list_from_opt(opt)\n",
    "    if opt.confirm:\n",
    "        confirm_opt(opt)\n",
    "    else:\n",
    "        print_opt(opt)\n",
    "#     save_opt(opt)\n",
    "    train(opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
